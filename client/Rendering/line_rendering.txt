What about rendering the lines (as quads with rounded edges) to a seperate texture and basically doing sdf operations on it? Can you read from a pixel you are going to be writing to? You can't read from pixels around it, but maybe you could read just the one you are writing to?


Rendering textured lines with thickness.

Search terms
* Ribbon particle/effect/emmiter
* Trail renderer/particle/effect/emmiter
* webgl lines
* opengl lines
* OpenVG
* NV_path_rendering
* thick ?(textured) line rendering
* Skeletal Strokes https://diglib.eg.org/bitstream/handle/10.2312/SBM.SBM10.033-040/033-040.pdf?sequence=1&isAllowed=n
https://dl.acm.org/doi/pdf/10.1145/192161.192186
* Rodeway generator https://forum.unity.com/threads/how-to-make-line-renderer-handle-textures-at-the-end-and-corner-vertices.1397746/

Nice demo https://hypertolosana.github.io/efficient-webgl-stroking/index.html

Implementations
* SDFs
* Triangulate the line into quads and triangles.

Not sure how the SDF implementation would get the texture coordinates. If you don't care about global self intersections the you just get the min of the SDFs and calculate the distance along the line that is closest to the point. One way you could handle self intersection is check if the distance of the lines that the min is checked between is smaller than some value the just do the regular method else render the one with the smaller distance along the line below and blend.
Incomplete shadertoy implementation below. (flickering probably caused by equal values and floating point precision limits)

Problems

Shape of the corners.
I wanted the shape to be smooth so I decided to when drawing the line from a to b to c create an circular arc of radius half the width of the line around b from angle of the line ab + 90deg to bc + 90deg(choosing the smaller arc between those two).
Unity creates an arc of radius equal to the width of the line around the intersection point of the thickned lines (line ab translated along the normal by half width both up and down). I implemented this in one of the commits, but there are several issues with it. Because when the angle is small the intersection point moves down the line won't contain the actual points. Also to join the lines when there is no intersection point you have to choose some other point.

If a line is not straight there are multiple ways to represent a point.
Solution: Make the texture position x constant along the joining arc.

Joining the lines when there is no intersection point.
What all the implementations I have seen do is to fully render both quads the issue is that this causes self intersections.

Self intersections also called overdraw or local self intersection in the problem of offsetting or folds in the problem skeletal strokes.
Self intersections are only an issue if the line is transparent.
Because the algorithm when generating only looks at 3 neighbouring vertices at a time self intersections will happen. Normal self intersections are wanted (the acutall not thickened line crosses another part of the line), but the buggy ones look bad.
Removing all self intersections.
Self intersections are causes by 2 triangles overlapping so this issue can be resolved by using order independent transparency. First render only to the depth buffer and the render the image with depthFunc = GL_EQUAL. This also removes the wanted self intersections, but you could try to handle it by rendering the self intersecting parts in different passes. It might be hard to actually find the wanted intersections. 
What should be the depth in OIT.
* Index of the generated vertex. Still causes some atrifacts on sharp turns
* (texturePosition.y - 0.5) * 2.0. This could probably be made too look good. Haven't figured it out yet. One side looks good the other looks bad and wanted self intersections break "Different method of removing self intersections" commit. It would probably be nice if I could write a custom depth writing function, which might be possible using depth textures. This method only works on clockwise or anticloswise angles. You can switch by doing 1.0 - texturePosition.y. Using abs won't work. The issue is that you would need to be able to switch based on the clockwisenss but one node can multiple for example in a 'Z' pattern ("Self intersection prevention glitch" commit).

PathOffsetting.
Something like http://www.angusj.com/clipper2/Docs/Units/Clipper/Functions/InflatePaths.htm might work, but this implementation might not work because it says Caution: Offsetting self-intersecting polygons may produce unexpected results.
Tested it clipper2 completly breaks on self intersecting polygons.
It might be hard to find a good offsetting algorithm, because most of them remove self intersections because they use clipping for example 

Inkscape just renders the full quads each time doesn't do any clipping. The texture is constant along the arc.

Boolean operations on polygons break remove the wanted self intersections.

// Not anything too helpful https://stackoverflow.com/questions/687173/how-do-i-render-thick-2d-lines-as-polygons

There are two types of self-intersections discussed in the literature, these are local and
global. Local self-intersections occur when the curvature of a surface is less than the offset
distance
// https://scholarsarchive.byu.edu/cgi/viewcontent.cgi?article=6292&context=etd

Unreal engine also has bugs examples: 
* https://cghow.com/trails-in-unreal-engine-niagara-component-renderer/
* https://youtu.be/Zn9-U5vQl3g?t=773
* https://youtu.be/Zn9-U5vQl3g (passing through to the middle. Are they using (texturePosition.y - 0.5) * 2.0 method? or is it because of 3d)
Apparently in 3d in the old system they tried to hide sharp edges by fading out whenever there was an edge.

Godot Line2D is quite broken there are breaks between the segments if the distances are small. Shaders for line2d: https://www.reddit.com/r/godot/comments/btsrxc/shaders_for_line2d_are_tricky_does_anyone_use_them/

Implementation examples
https://github.com/mattdesl/lwjgl-basics/wiki/LibGDX-Finger-Swipe#5-anti-aliasing-and-stroke-effects
https://wwwtyro.net/2021/10/01/instanced-lines-part-2.html
https://ivan.sanchezortega.es/development/2023/02/06/reinventing-line-joins.html
http://www.pixelvex.com/gamedev/trails
Faster anti aliasing https://github.com/tyt2y3/vaserenderer
http://artgrammer.blogspot.com/2011/05/drawing-nearly-perfect-2d-line-segments.html
http://artgrammer.blogspot.com/2011/07/drawing-polylines-by-tessellation.html
https://mattdesl.svbtle.com/drawing-lines-is-hard

Possible actual solution
There is a paper mentioned here https://news.ycombinator.com/item?id=9179336
"Shader-Based Antialiased, Dashed, Stroked Polylines" https://jcgt.org/published/0002/02/08/
and in this paper there is a mention of a metod of removing folds "Folding Avoidance in Skeletal Strokes" https://diglib.eg.org/bitstream/handle/10.2312/SBM.SBM10.033-040/033-040.pdf?sequence=1&isAllowed=n. 
The presented method doesn't really fully solve the problem (it does solve other problems that are useful) as you can see in the first picture of figure 19 if one segment is shorted the folding still happens. 
The actual solution might be to simplify the curve into a sequence of bezier curves like for example in blender curve draw. Add bezier curve an on the side there is an option for drawing. And then apply the algorithm in the paper. 
One issue might be coherency if points are removed espetially for static things like road wheel marks.
Another might be the mapping might skew things although it doesn't look like it from the rounded joints in figure 20.
Overdraw still might happen if you move forward and back on the same line.

"Shader-Based Antialiased, Dashed, Stroked Polylines"
The implementation always does the miter joint which sometimes causes weird issues.
On joins it advances the texture coordinates which creates discontinuities when using texture like for example hsv(uv.x, 1.0, 1.0) but looks very good when using things like dotted moving lines. The glitch is even visible on the continous demo which shows a smooth bezier curve with the hsv texture applied so it isn't only present in extreme cases. The examples given in "Folding Avoidance in Skeletal Strokes" might be using a different texturing method idk or maybe the hsv texture is just not a realistic example and other textures would look good.

Running the demo from "Shader-Based Antialiased, Dashed, Stroked Polylines" 
apt install python2
apt install pip2
pip install numpy
pip install PyOpenGl
sudo apt-get install freeglut3-dev https://github.com/Marxlp/pyFlightAnalysis/issues/10
On windows the whell packages need to have the right version of python. The version is in the filename. Was too lazy to make it work.
Checked and the demo doesn't handle the case shown in figure 19 of "Folding Avoidance in Skeletal Strokes". Aslo the presented method like it says only works for polylines not other curves.

Maybe push away the points where there is a fold to remove it.

For most practical purposes the self intersections shouldn't be much of an issue for static objects like road marks the OIT method would work, because it makes sense that doubly covered marks (intersecting) could be removed. And for trails the paths usually don't loop (trajectories) or are too short too loop.

This seems really good
"Line drawings from 3D models: a tutorial"
https://inria.hal.science/hal-02189483/file/contour_tutorial.pdf - chapter 9
Mentionted 
least-squares B-spline fit - example: https://www.geometrictools.com/Documentation/BSplineCurveLeastSquaresFit.pdf
blender freestyle maybe could find something in the source idk https://freestyle.sourceforge.io/download.php

Pattented?
https://patents.google.com/patent/US8941661B2/en

Joins
http://tavmjong.free.fr/SVG/LINEJOIN_STUDY/

https://gamedev.net/forums/topic/681039-theory-behind-these-uncharted-4-bullet-trails/5304804/

Haven't read
https://www.researchgate.net/publication/228803883_Real-Time_Offset_Surfaces_Extended_Version

Bezier curve offsetting
https://pomax.github.io/bezierinfo/#offsetting

https://www.codeproject.com/Articles/226569/Drawing-polylines-by-tessellation

https://www.heldermann-verlag.de/jgg/jgg12/j12h1odeh.pdf

https://www.youtube.com/watch?v=CawzHMXaCw4

https://www.youtube.com/watch?v=CNc9iNFQwzk

https://stackoverflow.com/questions/13841369/how-to-add-trail-path-for-moving-sprite-in-andengine

Not that related https://www.realtimerendering.com/blog/limits-of-triangles/

https://gamedev.stackexchange.com/questions/83861/how-can-i-create-a-contrail-effect-for-a-spaceship-in-motion
Chapter 9.3 Billboarding https://canvas.projekti.info/ebooks/Mathematics%20for%203D%20Game%20Programming%20and%20Computer%20Graphics,%20Third%20Edition.pdf

Physically-based Feature Line Rendering http://lines.rexwe.st/

Issues with other implementations
https://forum.unity.com/threads/why-are-trail-renderer-uvs-distorted.1173323/
https://forum.unity.com/threads/linerenderer-vertex-bug.978312/
https://realtimevfx.com/t/niagara-how-to-keep-a-ribbon-facing-a-direction-in-local-space-without-loosing-the-trail/12863
In other non unity games https://forum.unity.com/threads/how-do-i-prevent-particle-trail-bugs.448022/

Just finding a curve that satisfies the curbautre requirements might not be enough because the curve must be approximated by lines which always have infinite curvature at turns and there might be some issues with shorter like like in that figure.
Maybe could find something by searching something like constrainted interpolation idk.
"Interpolation with Curvature Constraints" https://inria.hal.science/inria-00072572/PDF/RR-4064.pdf
The curvature is the distance between a point and 2 normal of the points near the point in limiting position so it makes sense why this radius has to be bigger than half the width.

maybe something about coordinate systems on ruled surfaces

Rulled surface http://www.geometrie.tugraz.at/wallner/kurs.pdf

It is impossible to solve this problem by only looking locally (3 consecutive vertices) but global methods are slow (SDFs, other pixel shader methods like depth). Could hide glitches by making the curves smoother and the segments longer (so the local area is bigger) like for example using bezier fitting. Or making the curves thinner on sharp turns or fading them out.
Because it is possible to check using the radius of curvature is a curve is correct it might be possible in certain cases to remove the errors by smoothing.
Could use a subdivision algorithm like for example https://observablehq.com/@pamacha/chaikins-algorithm


Old

Because rounding is used to join 2 lines there is no way to assign texture coordinates to points on the line without streching them. The rounding arc is longer than the bottom part and adds to the x coordinate which means the to part travels more than the bottom part so to maintain lengths and not create discontinouties the texture cooridnates at the point opposite to the rounding would need to be constant and the points on the arc would need to add to x distance. This would make it so the distances on one side of the line would be bigger than on the bottom part, which would not be good for texturing (the top part would be skewed relative to the bottom). Unity handles this by making the x texture coordinate constant along the whole arc. This causes articafts, because the whole arc uses the same texture for example. I think the impossiblity of creating a coordinate system on a line without stretching might be a consequence of Theorema Egregium(This can't be true because everywhere where the curvature exists, which is everywhere except at the boundary the gaussian curvature is still zero 0, maybe there is some generalization to 2d shapes that is true). Straws need to be extendible to be able to bend nicely.

To calculate a width at a point you need the position along the line, this could be calculated for example, by adding up all the lengths of segments and dividing the current position by this length to get a value from 0 to 1. The issue is that to keep the textures the length acutally added won't be the actual length from the current point to the next so to keep the lenghts consistent a smaller value would need to be added to the x coordinate, but if a smaller value is added then the total length, changes, which means the the calculated position along the curve from 0 to 1 won't be correct. Another option would be to add the whole length even if it isn't the correct value the issue is that then the value of the width won't be the value it should be for the value of x. The issue is what should the value be at the start of the next line after the arc. Normally it should be the same. Can't just make it wider, because it would change the intersection point and also the correct width. Could interpolate the width along the arc. Not sure how other implementations handle this. In unity it doesn't seem that the length is interpolated along the arc. The only actual solution would probably be to intersect 2 curves instead of lines at these points so that the width changes correctly. It seems that the simplest way to handle this would be to change the width in the fragment shader. A fragment shader would probably need to be used anyway to do anti aliasing. And with differently changing values in the y direction the anti aliasing width would vary along the curve, which might not look correct. The only option to handle this with actually changing triangle width would probably require adding extra quads on both sides like here .

float lineSegmentSdf(vec2 p, vec2 start, vec2 end) {
    vec2 t = normalize(end - start);
    vec2 n = vec2(-t.y, t.x);
    float ld = dot(n, start);
    float d = dot(p, n) - ld;
    float dAlong = dot(p, t);
    float dAlongStart = dot(start, t);
    float dAlongEnd = dot(end, t);
    float along = clamp(dAlong, dAlongStart, dAlongEnd);
    vec2 cloestPointOnLine = along * t + ld * n;
    return distance(p, cloestPointOnLine);
}


float distanceAlong(vec2 p, vec2 start, vec2 end) {
    vec2 t = normalize(end - start);
    vec2 n = vec2(-t.y, t.x);
    float ld = dot(n, start);
    float d = dot(p, n) - ld;
    float dAlong = dot(p, t);
    float dAlongStart = dot(start, t);
    return dAlong - dAlongStart;
}

vec3 hsv2rgb(vec3 c) {
    vec4 K = vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);
    vec3 p = abs(fract(c.xxx + K.xyz) * 6.0 - K.www);
    return c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);
}

void mainImage( out vec4 fragColor, in vec2 fragCoord ) {
    vec2 p = fragCoord;
    p /= iResolution.xy;
    p -= vec2(0.5);
    p.x *= iResolution.x / iResolution.y;
    //float d = distance(vec2(0.0), p);
    float len = 0.35;
    float angle = 1.0 + iTime / 5.0;
    vec2 v0 = vec2(cos(angle), sin(angle)) * len;
    vec2 v1 = vec2(0.0);
    vec2 v2 = vec2(len, 0.0);
    float d0 = lineSegmentSdf(p, v0, v1);
    float d1 = lineSegmentSdf(p, v1, v2);
    float d;
    float x;
    if (d0 < d1) {
        d = d0;
        x = distanceAlong(p, v0, v1);
    } else {
        d = d1;
        x = distance(v1, v2) + distanceAlong(p, v1, v2);
    }
    d = min(d0, d1);
    d -= 0.1;
    d = smoothstep(0.0, 0.5, d);
    
    if (d <= 0.0) {
        fragColor = vec4(hsv2rgb(vec3(x * 5.0, 1.0, 1.0)), 1.0);
        //fragColor = vec4(1.0, 0.0, 0.0, 1.0);
    } else {
        fragColor = vec4(1.0);
    }
    
    //fragColor = vec4(vec3(d), 1.0);
}




















#define HASHSCALE 0.1031

float hash(float p)
{
	vec3 p3  = fract(vec3(p) * HASHSCALE);
    p3 += dot(p3, p3.yzx + 19.19);
    return fract((p3.x + p3.y) * p3.z);
}

float fade(float t) { return t*t*t*(t*(6.*t-15.)+10.); }

float grad(float hash, float p)
{
    int i = int(1e4*hash);
	return (i & 1) == 0 ? p : -p;
}

float perlin(float p)
{
	float pi = floor(p), pf = p - pi, w = fade(pf);
    return mix(grad(hash(pi), pf), grad(hash(pi + 1.0), pf - 1.0), w) * 2.0;
}

float perlin01(float p)
{
	return (perlin(p) + 1.0) * 0.5;
}

#define M_PI 3.14159265358979323846

float rand(vec2 co){return fract(sin(dot(co.xy ,vec2(12.9898,78.233))) * 43758.5453);}
float rand (vec2 co, float l) {return rand(vec2(rand(co), l));}
float rand (vec2 co, float l, float t) {return rand(vec2(rand(co, l), t));}

float perlin(vec2 p, float dim, float time) {
	vec2 pos = floor(p * dim);
	vec2 posx = pos + vec2(1.0, 0.0);
	vec2 posy = pos + vec2(0.0, 1.0);
	vec2 posxy = pos + vec2(1.0);
	
	float c = rand(pos, dim, time);
	float cx = rand(posx, dim, time);
	float cy = rand(posy, dim, time);
	float cxy = rand(posxy, dim, time);
	
	vec2 d = fract(p * dim);
	d = -0.5 * cos(d * M_PI) + 0.5;
	
	float ccx = mix(c, cx, d.x);
	float cycxy = mix(cy, cxy, d.x);
	float center = mix(ccx, cycxy, d.y);
	
	return center * 2.0 - 1.0;
}

// p must be normalized!
float perlin(vec2 p, float dim) {
	
	vec2 pos = floor(p * dim);
	vec2 posx = pos + vec2(1.0, 0.0);
	vec2 posy = pos + vec2(0.0, 1.0);
	vec2 posxy = pos + vec2(1.0);
		
	float c = rand(pos, dim);
	float cx = rand(posx, dim);
	float cy = rand(posy, dim);
	float cxy = rand(posxy, dim);
	
	vec2 d = fract(p * dim);
	d = -0.5 * cos(d * M_PI) + 0.5;
	
	float ccx = mix(c, cx, d.x);
	float cycxy = mix(cy, cxy, d.x);
	float center = mix(ccx, cycxy, d.y);
	
	return center * 2.0 - 1.0;
	return perlin(p, dim, 0.0);
}

vec2 hash(vec2 p)
{
	p = vec2( dot(p,vec2(127.1,311.7)), dot(p,vec2(269.5,183.3)) );
	return -1.0 + 2.0*fract(sin(p)*43758.5453123);
}

float perlin(vec2 p)
{
    const float K1 = 0.366025404; // (sqrt(3)-1)/2;
    const float K2 = 0.211324865; // (3-sqrt(3))/6;

	vec2  i = floor( p + (p.x+p.y)*K1 );
    vec2  a = p - i + (i.x+i.y)*K2;
    float m = step(a.y,a.x); 
    vec2  o = vec2(m,1.0-m);
    vec2  b = a - o + K2;
	vec2  c = a - 1.0 + 2.0*K2;
    vec3  h = max( 0.5-vec3(dot(a,a), dot(b,b), dot(c,c) ), 0.0 );
	vec3  n = h*h*h*h*vec3( dot(a,hash(i+0.0)), dot(b,hash(i+o)), dot(c,hash(i+1.0)));
    return dot( n, vec3(70.0) );
}

float perlin01(vec2 p)
{
	return (perlin(p) + 1.0) * 0.5;
}

float octave01(vec2 p, int octaves) {
	int OCTAVES = 4;
    float amplitude = .5;
    float frequency = 0.;
	float value = 0.0;
    for (int i = 0; i < OCTAVES; i++) {
        value += amplitude * perlin01(p);
        p *= 2.;
        amplitude *= .5;
    }
	return value;
}

float lineSegmentSdf(vec2 p, vec2 start, vec2 end) {
    vec2 t = normalize(end - start);
    vec2 n = vec2(-t.y, t.x);
    float ld = dot(n, start);
    float d = dot(p, n) - ld;
    float dAlong = dot(p, t);
    float dAlongStart = dot(start, t);
    float dAlongEnd = dot(end, t);
    float along = clamp(dAlong, dAlongStart, dAlongEnd);
    vec2 cloestPointOnLine = along * t + ld * n;
    return distance(p, cloestPointOnLine);
}


float distanceAlong(vec2 p, vec2 start, vec2 end) {
    vec2 t = normalize(end - start);
    vec2 n = vec2(-t.y, t.x);
    float ld = dot(n, start);
    float d = dot(p, n) - ld;
    float dAlong = dot(p, t);
    float dAlongStart = dot(start, t);
    return dAlong - dAlongStart;
}

vec3 hsv2rgb(vec3 c) {
    vec4 K = vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);
    vec3 p = abs(fract(c.xxx + K.xyz) * 6.0 - K.www);
    return c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);
}

void mainImage( out vec4 fragColor, in vec2 fragCoord ) {
    vec2 p = fragCoord;
    p /= iResolution.xy;
    p -= vec2(0.5);
    p.x *= iResolution.x / iResolution.y;
    //float d = distance(vec2(0.0), p);
    float len = 0.3;
    vec2 v0 = vec2(0.0f, len);
    vec2 v1 = vec2(0.0, -len);
    float d = lineSegmentSdf(p, v0, v1);
    d += 0.05;
    d = smoothstep(0.0, 0.5, d);
    //d *= 2.0;
    p.x += iTime / 2.0;
    //d /= octave01(p * 3.0, 4);
    d /= octave01(p * 3.0, 4);
    fragColor = vec4(vec3(d), 1.0);
}





















#define HASHSCALE 0.1031

float hash(float p)
{
	vec3 p3  = fract(vec3(p) * HASHSCALE);
    p3 += dot(p3, p3.yzx + 19.19);
    return fract((p3.x + p3.y) * p3.z);
}

float fade(float t) { return t*t*t*(t*(6.*t-15.)+10.); }

float grad(float hash, float p)
{
    int i = int(1e4*hash);
	return (i & 1) == 0 ? p : -p;
}

float perlin(float p)
{
	float pi = floor(p), pf = p - pi, w = fade(pf);
    return mix(grad(hash(pi), pf), grad(hash(pi + 1.0), pf - 1.0), w) * 2.0;
}

float perlin01(float p)
{
	return (perlin(p) + 1.0) * 0.5;
}

#define M_PI 3.14159265358979323846

float rand(vec2 co){return fract(sin(dot(co.xy ,vec2(12.9898,78.233))) * 43758.5453);}
float rand (vec2 co, float l) {return rand(vec2(rand(co), l));}
float rand (vec2 co, float l, float t) {return rand(vec2(rand(co, l), t));}

float perlin(vec2 p, float dim, float time) {
	vec2 pos = floor(p * dim);
	vec2 posx = pos + vec2(1.0, 0.0);
	vec2 posy = pos + vec2(0.0, 1.0);
	vec2 posxy = pos + vec2(1.0);
	
	float c = rand(pos, dim, time);
	float cx = rand(posx, dim, time);
	float cy = rand(posy, dim, time);
	float cxy = rand(posxy, dim, time);
	
	vec2 d = fract(p * dim);
	d = -0.5 * cos(d * M_PI) + 0.5;
	
	float ccx = mix(c, cx, d.x);
	float cycxy = mix(cy, cxy, d.x);
	float center = mix(ccx, cycxy, d.y);
	
	return center * 2.0 - 1.0;
}

// p must be normalized!
float perlin(vec2 p, float dim) {
	
	vec2 pos = floor(p * dim);
	vec2 posx = pos + vec2(1.0, 0.0);
	vec2 posy = pos + vec2(0.0, 1.0);
	vec2 posxy = pos + vec2(1.0);
		
	float c = rand(pos, dim);
	float cx = rand(posx, dim);
	float cy = rand(posy, dim);
	float cxy = rand(posxy, dim);
	
	vec2 d = fract(p * dim);
	d = -0.5 * cos(d * M_PI) + 0.5;
	
	float ccx = mix(c, cx, d.x);
	float cycxy = mix(cy, cxy, d.x);
	float center = mix(ccx, cycxy, d.y);
	
	return center * 2.0 - 1.0;
	return perlin(p, dim, 0.0);
}

vec2 hash(vec2 p)
{
	p = vec2( dot(p,vec2(127.1,311.7)), dot(p,vec2(269.5,183.3)) );
	return -1.0 + 2.0*fract(sin(p)*43758.5453123);
}

float perlin(vec2 p)
{
    const float K1 = 0.366025404; // (sqrt(3)-1)/2;
    const float K2 = 0.211324865; // (3-sqrt(3))/6;

	vec2  i = floor( p + (p.x+p.y)*K1 );
    vec2  a = p - i + (i.x+i.y)*K2;
    float m = step(a.y,a.x); 
    vec2  o = vec2(m,1.0-m);
    vec2  b = a - o + K2;
	vec2  c = a - 1.0 + 2.0*K2;
    vec3  h = max( 0.5-vec3(dot(a,a), dot(b,b), dot(c,c) ), 0.0 );
	vec3  n = h*h*h*h*vec3( dot(a,hash(i+0.0)), dot(b,hash(i+o)), dot(c,hash(i+1.0)));
    return dot( n, vec3(70.0) );
}

float perlin01(vec2 p)
{
	return (perlin(p) + 1.0) * 0.5;
}

float octave01(vec2 p, int octaves) {
	int OCTAVES = 4;
    float amplitude = .5;
    float frequency = 0.;
	float value = 0.0;
    for (int i = 0; i < OCTAVES; i++) {
        value += amplitude * perlin01(p);
        p *= 2.;
        amplitude *= .5;
    }
	return value;
}

float lineSegmentSdf(vec2 p, vec2 start, vec2 end) {
    vec2 t = normalize(end - start);
    vec2 n = vec2(-t.y, t.x);
    float ld = dot(n, start);
    float d = dot(p, n) - ld;
    float dAlong = dot(p, t);
    float dAlongStart = dot(start, t);
    float dAlongEnd = dot(end, t);
    float along = clamp(dAlong, dAlongStart, dAlongEnd);
    vec2 cloestPointOnLine = along * t + ld * n;
    return distance(p, cloestPointOnLine);
}


float distanceAlong(vec2 p, vec2 start, vec2 end) {
    vec2 t = normalize(end - start);
    vec2 n = vec2(-t.y, t.x);
    float ld = dot(n, start);
    float d = dot(p, n) - ld;
    float dAlong = dot(p, t);
    float dAlongStart = dot(start, t);
    return dAlong - dAlongStart;
}

vec3 hsv2rgb(vec3 c) {
    vec4 K = vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);
    vec3 p = abs(fract(c.xxx + K.xyz) * 6.0 - K.www);
    return c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);
}

void mainImage( out vec4 fragColor, in vec2 fragCoord ) {
    vec2 p = fragCoord;
    p /= iResolution.xy;
    p -= vec2(0.5);
    p.x *= iResolution.x / iResolution.y;
    //float d = distance(vec2(0.0), p);
    float len = 0.3;
    vec2 v0 = vec2(0.0f, len);
    vec2 v1 = vec2(0.0, -len);
    float d = lineSegmentSdf(p, v0, v1);
    d -= + p.y / 4.0;
    d += 0.01;
    d = smoothstep(0.0, 0.5, d);
    //d *= 2.0;
    //p.x += iTime / 2.0;
    //d /= octave01(p * 3.0, 4);
    //d /= octave01(p * 3.0, 4);
    p.y += iTime;
    d /= octave01(p * 3.0, 4);
    p.x += iTime;
    d += octave01(p * 2.0, 1);
    d = 1.0 - d;
    fragColor = vec4(vec3(d), 1.0);
}